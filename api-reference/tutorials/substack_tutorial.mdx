---
title: "Dynamically Creating Custom GPT-4 Instances for Substack Blog Posts with BerriAI"
description: "This tutorial will guide you on how to use BerriAI to create custom GPT-4 Instances for Substack blog posts in a few simple steps."
---

In this tutorial, you will learn how to use BerriAI to create custom GPT-4 instances for 
Substack blog posts by inputting a blog URL.

## Step 1: Create a Template to use the specified Prompt
The first step is to create a template where you can configure your instances. 
You can use your template to specify the prompt to use (eg You are a Pirate who will help with legal documents) and 
if the instance will be used for doing question answering over documents, input URLs or 
data analysis. 
You can also use the same template for all the instances you create in step 2.

You can specify the prompt and intent when creating the template. 
In this tutorial, you will create a template using the following code snippet:

```python
import requests
import json

## create template
prompt = """
Context information is below.
---------------------
{context_str}
---------------------
You are an AI assistant for answering questions from substack blog posts, 
given the context information and no prior knowledge, 
generate the answer for {query_str} by answering like Yoda
"""

# store template id
url = "https://api.berri.ai/create_template"
data = {
  "advanced": {
    "intent": "qa_website",
  },
  "prompt": prompt
}

response = requests.post(url, data={"app_config": json.dumps(data)})

print(response.text)

template_id = response.json()["template_id"]

```

- In the code above, we first define the prompt for the template. 
- We then send a request to BerriAI's create_template endpoint with the prompt as the payload. 
- The response will contain a JSON object with a template_id key, which we will store for later use.


## Step 2: Create an Instance Using an Existing Template
Next, create an instance of the template you just created. 
An instance is a custom GPT-4 app that is fine-tuned to the data source specified. 
In this case, you will create an instance of the GPT-4 app for a 
specific Substack blog post.

```python
template_id = "6913bf12-9ec7-4255-8f4d-00e7207dd0b0"
input_url = "https://janvikalra.substack.com/p/learning-1-i-know-nothing"

## create instance using existing template id
url = "https://api.berri.ai/create_app"
data = {
  "template_id": template_id,
  "user_email": "ishaan@berri.ai",
  "data_source": input_url
}
response = requests.post(url, data=data)
print(response.text)
api_endpoint = response.json()["api_endpoint"]

```
In the code above, you first define the template_id that you retrieved in the previous step.
You then define the input_url, which is the Substack blog post that you want to generate the app for.
You then send a request to BerriAI's create_app endpoint with the template_id, user_email, and data_source as the payload.
You should specify your own email if you are a developer building with Berri


## Step 3: Dynamic Instance Generation + Get off localhost - Create a Flask Server 
Step 3 of the tutorial is to create a server that can dynamically generate GPT-4 instances for each subsequent blog post. 
To achieve this, we can utilize the Berri API endpoint to generate these instances on the fly. 
Here is the Flask app code for this purpose:

```python
from flask import Flask, request
import requests

app = Flask(__name__)

template_id = "be22ee2e-2186-4406-b45c-53e69306c3c4"
url = "https://api.berri.ai/create_app"


@app.route('/')
def hello():
  return 'Hello from my Flask app!'


@app.route('/create-app', methods=['POST'])
def create_app():

  input_url = request.form.get('input_url')
  print(input_url)
  data = {
    "template_id": template_id,
    "user_email": "ishaan@berri.ai",
    "data_source": input_url
  }
  response = requests.post(url, data=data)
  print(response.json())
  api_endpoint = response.json()["api_endpoint"]
  return response.json()


if __name__ == "__main__":
  from waitress import serve
  serve(app, host="0.0.0.0", port=5000)


```
- This app uses code from Step 2 and is converted into a Flask app.
- A template ID is already available and input URLs are dynamically set.
- The Flask server listens for HTTP POST requests on the /create-app endpoint.
- When it receives a request, it extracts the input URL from the form data.
- The Flask app sends a POST request to the Berri API endpoint with appropriate parameters, including the template ID, user email, and input URL, which varies based on the substack blog post.
- The response JSON from the Berri API includes the api_endpoint and website_endpoint, which is returned to the caller of the /create-app endpoint.
- An example response for this substack https://substack.com/inbox/post/109167394
```
{
    "api_endpoint": "https://shareddbstorequery-7bea-8hjw.zeet-berri.zeet.app/berri_query?proj_path=indexes/ishaan@berri.ai/4bb13867-d3f1-40a9-b20a-4ef3f2f532a8&query=",
    "website_endpoint": "chat.berri.ai/aHR0cHM6Ly9zaGFyZWRkYnN0b3JlcXVlcnktN2JlYS04aGp3LnplZXQtYmVycmkuemVldC5hcHAvYmVycmlfcXVlcnk_cHJval9wYXRoPWluZGV4ZXMvaXNoYWFuQGJlcnJpLmFpLzRiYjEzODY3LWQzZjEtNDBhOS1iMjBhLTRlZjNmMmY1MzJhOA=="
}
```

Future steps:
Make a full-stack app by adding a frontend to call your Flask server. Consider using React or Vue. Here's a starting point: https://replit.com/join/ceztxyemli-ishaan-jaff
Customize the chat.berri.ai interface for your application. Add your own branding and keep the necessary features.
Chat.berri.ai is open-sourced on GitHub. Check it out here: https://github.com/ClerkieAI/Berri-chat-fe.