---
title: "Query App"
api: "GET https://api.berri.ai/query"
description: "How to query your Berri Endpoint"
---

### Query

<ParamField query="user_email" type="string">
  The email address you are using on your berri.ai account Example:
  ishaan@berri.ai
</ParamField>
<ParamField query="instance_id" type="string">
  The instance you want to query, create_app returns an instance_id that you can
  query here
</ParamField>
<ParamField query="query" type="string">
  The query for your instance Example: "Who is ishaan?"
</ParamField>
<ParamField query="rationale" type="string">
  The model is prompted to come up with a rationale/think before giving it's answer. 
  The returned format is: Rationale: <model rationale> Answer: <model answer>. 
  Can help improve accuracy by up to 30%. 
</ParamField>
<ParamField query="model" type="string" optional>
  There are currently 4 types of models Berri supports.

**GPT 3**
`model: text-davinci-003`

**[RECOMMENDED] chat GPT**
`model: gpt-3.5-turbo`

**GPT 4**
`model: gpt-4`

**T5**
`model: t5`

t5 is recommended for those looking for an on-prem alternative to GPT.

Try out the different models for your data: https://play.berri.ai/ ðŸš€

</ParamField>
<ParamField query="top_k" type="number" optional>
  All your data cannot fit into GPT's context window. So we break it into chunks and give GPT the most relevant chunk at query time. Use this parameter to control how many chunks of data you want to give GPT. By default this is set to `1`.

Setting `top_k = 1` is the same as saying `For a given question, only give the most similar chunk of data to GPT`.
Setting `top_k = 2` is the same as saying `For a given question, give the top 2 most similar chunk of data to GPT`.

</ParamField>
<ParamField query="history" type="string" optional>
  You can also choose to pass in the chat history as part of your query request. We expect this to be a list that is converted to a JSON String.

**How is this being parsed by our API?**
Our server is a Flask app, and we check if history exists, and if it does we try and evaluate if the JSON string passed is a list.

`history = request.args.get('history')`
`history = ast.literal_eval(history)`

**How does this impact your query?**
When you pass in history, we summarize it and pass it as additional context (in addition to your query) to the model you selected.

</ParamField>

<RequestExample>

```python python
import requests

url = "https://api.berri.ai/query"

querystring = {
"user_email": "ishaan@berri.ai",
"instance_id": "6663d98e-f3e2-42b9-a79e-2d92199b85fa",
"query": "who is ishaan",
"model": "gpt-3.5-turbo"
}

response = requests.get(url, params=querystring)

print(response.text)

```

```javascript javascript
const axios = require("axios").default;

const url = "https://api.berri.ai/query";

const params = {
  user_email: "ishaan@berri.ai",
  instance_id: "6663d98e-f3e2-42b9-a79e-2d92199b85fa",
  query: "who is ishaan",
  model: "gpt-3.5-turbo",
};

axios
  .get(url, { params })
  .then((response) => {
    console.log(response.data);
  })
  .catch((error) => {
    console.error(error);
  });
```

</RequestExample>
